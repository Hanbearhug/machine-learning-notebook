本文机器学习的知识
## kernel LR
链接 ========> https://shomy.top/2017/03/07/kernel-lr/  

## 优化器总结  
链接 ========> https://blog.csdn.net/u010089444/article/details/76725843
### sgd
#### Batch Gradient Descent
每一轮迭代中，用整个训练集的数据计算梯度，然后更新参数。  
Θ=Θ−α⋅▽Θ​J(Θ)  


